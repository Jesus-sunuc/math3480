{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Nearest Neighbors\n",
    "__MATH 3480__ - Dr. Michael Olson\n",
    "\n",
    "Reading:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Machine Learning Landscape](https://raw.githubusercontent.com/drolsonmi/math3480/main/Notes/Images/3480_05_ML_Landscape.png)\n",
    "\n",
    "## The Concept behing k-Nearest Neighbors\n",
    "The k-Nearest Neighbors (KNN) algorithm takes a point and gives it a classification based on the characteristics of points near it.\n",
    "* Example: Cats have sharper claws and shorter ears, dogs have less sharp claws and longer ears\n",
    "    * Graph this on the board, then add another unknown point \n",
    "\n",
    "The value of $k$ tells KNN to look at the $k$ nearest points.\n",
    "* Count the number of neighbors with each category\n",
    "* The category with the highest count becomes the classification of our point in question\n",
    "\n",
    "As $k$ changes, it could change the result. How do we know what value of $k$ to use? This is kind of arbitrary, but we generally use the following rules\n",
    "* $k = \\sqrt{n}$\n",
    "* If $k$ is even, we could be equally balanced between two categories\n",
    "* If $k$ is a multiple of the number of groups to classify, we could be equally balanced between all categories\n",
    "* Put it all together $\\to$ choose an prime $k$ near $\\sqrt{n}$\n",
    "\n",
    "How do we determine the distance? We have many different distance measures:\n",
    "* Manhattan distance (L1-norm)\n",
    "* Euclidean distance (L2-norm)\n",
    "* L- $\\infty$ norm \n",
    "* Cosine distance\n",
    "* Jaccard distance (if we are dealing with categorical variables)\n",
    "\n",
    "The standard (default) option is generally the euclidean distance.\n",
    "  * For 2 variables: $d = \\sqrt{(x_0-x_{i0})^2 + (x_1-x_{i1})^2}$\n",
    "  * For 3 variables: $d = \\sqrt{(x_0-x_{i0})^2 + (x_1-x_{i1})^2 + (x_2-x_{i2})^2}$\n",
    "  * For 4 variables: $d = \\sqrt{(x_0-x_{i0})^2 + (x_1-x_{i1})^2 + (x_2-x_{i2})^2 + (x_3-x_{i3})^2}$\n",
    "  * etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Random Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_gaussian_quantiles\n",
    "\n",
    "X, y = make_gaussian_quantiles(n_features=2, n_classes=3, random_state=0)\n",
    "\n",
    "for grp,color in zip([0,1,2],['orange','green','blue']):\n",
    "    X_grp = X[y==grp]\n",
    "    plt.scatter(X_grp[:, 0], X_grp[:, 1], c=color, label=grp)\n",
    "\n",
    "plt.title(\"Gaussian divided into three quantiles\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[:10])\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "k = 11\n",
    "\n",
    "knn_class = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\n",
    "knn_class.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array([[0.7,-0.5],\n",
    "                    [0.5,0.5],\n",
    "                    [-1.3,0.7],\n",
    "                    [-1,-1.4]])\n",
    "\n",
    "X, y = make_gaussian_quantiles(n_features=2, n_classes=3, random_state=0)\n",
    "\n",
    "for grp,color in zip([0,1,2],['orange','green','blue']):\n",
    "    X_grp = X[y==grp]\n",
    "    plt.scatter(X_grp[:, 0], X_grp[:, 1], c=color, label=grp)\n",
    "\n",
    "plt.scatter(x_test[:,0], x_test[:,1], c='red', marker='*')\n",
    "\n",
    "for i in range(len(x_test)):\n",
    "    plt.annotate(i,(x_test[i,0], x_test[i,1]))\n",
    "\n",
    "plt.title(\"Gaussian divided into three quantiles\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = knn_class.predict(x_test)\n",
    "\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "The kNN model can be used as a regressor as well to predict the value of a point. For your point $x$, it will predict $\\hat{y}$ to be the average of the $y$ values of the nearest $k$ points.\n",
    "$$\\hat{y} = \\frac{1}{k}\\sum_{j=1}^k y_j$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = np.random.rand(100,2)*10\n",
    "x = X[:,0]\n",
    "y = X[:,1] + x**2\n",
    "\n",
    "plt.scatter(x,y)\n",
    "print(x[:10].reshape(-1,1))\n",
    "print(x[:10].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knr = KNeighborsRegressor(n_neighbors=2)\n",
    "knr.fit(x.reshape(-1, 1),y)\n",
    "\n",
    "y_pred = knr.predict(x.reshape(-1, 1))\n",
    "\n",
    "plt.scatter(x,y, c='blue')\n",
    "plt.scatter(x,y_pred, c='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.random.rand(10)*10\n",
    "y_test = knr.predict(x_test.reshape(-1,1))\n",
    "\n",
    "\n",
    "plt.scatter(x,y, c='blue')\n",
    "plt.scatter(x_test,y_test, c='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Iris Flower Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "list(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris['feature_names'])\n",
    "print(iris['data'][:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris['target_names'])\n",
    "print(iris['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "iris_df = pd.DataFrame(iris['data'], columns=iris['feature_names'])\n",
    "\n",
    "def species_name(x):\n",
    "    return iris['target_names'][x]\n",
    "\n",
    "iris_df['Species'] = pd.Series(iris['target']).apply(species_name)\n",
    "display(iris_df)\n",
    "\n",
    "sns.pairplot(iris_df, hue='Species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(iris_df,\n",
    "                x='petal length (cm)',\n",
    "                y='petal width (cm)',\n",
    "                hue='Species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "scatter = ax.scatter(iris['data'][:,0],\n",
    "                iris['data'][:,2],\n",
    "                iris['data'][:,3],\n",
    "                c=iris['target'])\n",
    "          \n",
    "ax.set_xlabel('Sepal Length (cm)')\n",
    "ax.set_ylabel('Petal Length (cm)')\n",
    "ax.set_zlabel('Petal Width (cm)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "1. Missing Data - No missing values in this example\n",
    "2. Encode Categorical Variables - Using original data, no categorical variables\n",
    "3. Split the data\n",
    "4. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b3e0e64",
   "metadata": {},
   "source": [
    "# Lecture 2 Data Handling\n",
    "__MATH 3480__ - Dr. Michael Olson\n",
    "\n",
    "Outline:\n",
    "* Obtaining Data\n",
    "* Loading Data\n",
    "* Cleaning Data\n",
    "   * Missing Labels\n",
    "   * Missing Values\n",
    "* Data Wrangling\n",
    "   * Joins and Merges\n",
    "\n",
    "Reading\n",
    "* Geron, Chapter 2 (pp. 42-51, 62-72)\n",
    "* KcKinney, Chapter 7 (pp. 203-209), Chapter 8 (pp. 253-268)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39963381-e675-4e2d-931e-22be40dfd728",
   "metadata": {},
   "source": [
    "## Obtaining Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4370585a-762c-4355-adad-45d4f500a915",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "From Math 3080, we saw the following ways to obtain data:\n",
    "* Online websites (Kaggle, Data Centers)\n",
    "* Web scraping\n",
    "* Application Programming Interfaces (APIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75d437a-b1c1-404f-9315-2912704c8dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "###   Online Websites   ###\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Crime Statistics between 2000 and 2020 - Used in Math 3080\n",
    "# https://github.com/drolsonmi/math3080/blob/main/Datasets/Crime_Statistics_2000-2020.csv\n",
    "\n",
    "crimes = pd.read_csv('https://raw.githubusercontent.com/drolsonmi/math3080/main/Datasets/Crime_Statistics_2000-2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d2429c-d6c6-4957-902f-bb5aec48890c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###   Web Scraping   ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c2f711-31db-4966-8022-97a1100d7f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "###   APIs   ###\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# First, you need to register for an account with the website supplying the API.\n",
    "# When registering, you will need an authorization key\n",
    "\n",
    "url = \"https://api.yelp.com/v3/businesses/search\"\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer hZU3WOBIK3jklJqIzew0uDFK_vjSYmoKToQQejrQuceKPGu8SF6M_-SuAT7asN6RNldA_kZvQGrE-3vh-RuQxHxRNUUKkHeRk03p_RLCQcO6ZZvHKMHoR5sEh7f3Y3Yx\"\n",
    "}\n",
    "\n",
    "params = {\n",
    "    \"term\" : \"restaurants\",\n",
    "    #\"latitude\" : 40.77,\n",
    "    #\"longitude\" : -111.9,\n",
    "    \"location\" : \"Ephraim, UT\",\n",
    "    \"radius\" : 5000,                  ## Units????\n",
    "    \"limit\" : 50\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b04d5ca-b098-46e0-9951-15e9122bb259",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cff191-0da3-4f99-9f72-95873ecc2e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "## From Seaborn\n",
    "import seaborn as sns\n",
    "iris = sns.load_dataset('iris')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64000ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "## From SciKit-Learn\n",
    "from sklearn.datasets import load_iris\n",
    "iris2 = load_iris()\n",
    "\n",
    "iris_df = pd.DataFrame(iris2['data'], columns=iris2['feature_names'])\n",
    "iris_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756f2e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## From a File\n",
    "X = np.loadtxt('Data/X.txt')                      # Numpy array\n",
    "ins = pd.read_csv('Data/insurance.csv', sep=\",\")  # Pandas DataFrame\n",
    "\n",
    "\n",
    "## From a website\n",
    "crimes = pd.read_csv('https://raw.githubusercontent.com/drolsonmi/math3080/main/Datasets/Crime_Statistics_2000-2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fb03b7-737f-4605-8783-1337235b998c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###  Example from Geron textbook that automates the entire process  ###\n",
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "# This function creates a datasets/housing subdirectory on your computer, then\n",
    "# downloads the file into that directory\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()\n",
    "\n",
    "# This function opens up the dataset\n",
    "import pandas as pd\n",
    "\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d2b206-69bd-4dc1-89d2-6993c4860389",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_housing_data()            # Download the file\n",
    "housing = load_housing_data()   # Load the file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e5daa6-8ca5-4a4d-9df5-69d91f8d6611",
   "metadata": {},
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bbe713-ca5b-4616-8b82-df765757b989",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Problems that can come up with data:\n",
    "* Unlabelled data\n",
    "* Missing data\n",
    "* Unorganized data\n",
    "\n",
    "All data needs to be labelled. If the labels aren't in the file, then there should be another file that explains the data. Labels are often described in\n",
    "* separate README file\n",
    "* top of the data file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8650128d",
   "metadata": {},
   "source": [
    "\n",
    "Ways that missing data could be indicated:\n",
    "* An extreme number (9999, -9999)\n",
    "* NaN (Not a Number)\n",
    "* Blank entry (no information) - programs usually fill these with NaN\n",
    "\n",
    "Let's use the dataset of Titanic passengers. We'll load them below. Data descriptions found at [https://campus.lakeforest.edu/frank/FILES/MLFfiles/Bio150/Titanic/TitanicMETA.pdf](https://campus.lakeforest.edu/frank/FILES/MLFfiles/Bio150/Titanic/TitanicMETA.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccaaf9c-8f92-43d3-9cbf-d586683d8c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "X, y = fetch_openml(\"titanic\", version=1, as_frame=True, return_X_y=True, parser='auto')\n",
    "\n",
    "df = X.copy()\n",
    "df['survived'] = y\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bbabdb-067c-40c9-bea5-5b64cbe788fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d93030c-82b4-4441-9341-3f68a9b9daff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48293664-2289-456e-8c44-1777ef013904",
   "metadata": {},
   "source": [
    "Determine if there are any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b8ee52-0c93-4567-ac69-7a5c3d6120e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9798d855-94ad-418e-b198-f767ba3272b1",
   "metadata": {},
   "source": [
    "Solutions to missing data:\n",
    "* Drop the observations\n",
    "   * If there are a large number of observations and only a few have missing values\n",
    "* Drop the variable\n",
    "   * If there are an extremely large percentage of data from a given variable that are missing\n",
    "* Fill in ...\n",
    "   * ... with variable mean\n",
    "   * ... with variable maximum\n",
    "   * ... with variable minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551a1fa3-fb7b-48c8-8272-44ce58aa42c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop variables\n",
    "df.drop('body', axis=1, inplace=True)\n",
    "        \n",
    "# Drop observations\n",
    "df['age'].dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5f0466-ba01-4ed0-aa28-5538726a5989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in with variable mean\n",
    "## Simple Method\n",
    "df['fare'].fillna(df['fare'].mean(), inplace=True)\n",
    "  # Can also use `axis=1` to do this for all numerical columns\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb296809-b78f-420d-ba7d-c9f5d5c84f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in with variable mean\n",
    "## Machine Learning Method\n",
    "  # Can be applied to multiple columns at the same time\n",
    "\n",
    "# import the SimpleImputer class from the impute module of the sklearn library\n",
    "from sklearn.impute import SimpleImputer \n",
    "\n",
    "# Create an object using the SimpleImputer class\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "imputer.fit(X['fare'].values.reshape(-1,1))\n",
    "X['fare'] = imputer.transform(X['fare'].values.reshape(-1,1))\n",
    "\n",
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedda285-5326-41a0-8c5c-ec05ea6f27a1",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056aaeee-c77f-49f6-adc0-5830394fac96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

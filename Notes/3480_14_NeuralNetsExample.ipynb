{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 14 Neural Network Example\n",
    "__MATH 3480__ - Dr. Michael Olson\n",
    "\n",
    "Reading:\n",
    "* Geron, Chapter 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build an ANN, we first create our input and output layers.\n",
    "\n",
    "### Input\n",
    "How many datapoints are going into the model? \n",
    "\n",
    "In the MNIST dataset, each image had a resolution of 28x28, or a total of 28*28=784 pixels. So, our input layer has a width of 784, one node for each pixel.\n",
    "\n",
    "### Output\n",
    "What is the desired output? How many nodes are needed to represent that output?\n",
    "\n",
    "In the MNIST dataset, the images are of numerical digits. So, the output is going to be any of the 10 digit. If we create 10 nodes (one for each digit), then we can use a Logistic/Softmax activation function to get a probability between 0 and 1. So, our output layer will have a width of 10.\n",
    "\n",
    "### Hidden layers\n",
    "Now, we determine the hidden layers. We have to decide how many hidden layers are needed and the width of each hidden layer.\n",
    "\n",
    "#### Number of hidden layers\n",
    "One hidden layer is generally enough, but deep neural networks (more than one hidden layer) have a higher parameter efficiency. Deep networks can use exponentially fewer neurons than shallow networks. Some rules of thumb:\n",
    "* lower hidden layers (layers near the input) model low-level structures (e.g., line segments of various shapes and orientations)\n",
    "* intermediate hidden layers combine these low-level structures to model intermediate-level structures (e.g., squares, circles)\n",
    "* Higher hidden layers (layers near the output) model high-level structures (e.g., faces)\n",
    "\n",
    "*Transfer learning*: using lower layers from one model in another situation. For example, using the lower layers in the above example to recognize line segments, then build a network to identify animals instead of faces.\n",
    "\n",
    "#### Width of hidden layers\n",
    "Early models used a pyramid structure - larger layers leading to gradually smaller layers. Experience has shown this really doesn't perform any better than layers with the same number of neurons. In fact, equally-sized layers tend to perform slightly better than decreasing layers.\n",
    "\n",
    "Generally, we do start with a larger first hidden layer, then shrink to a smaller layer and keep other hidden layers roughly the same size.\n",
    "\n",
    "In the past, programmers would retrain NNs, gradually increasing the number of neurons, until the model starts to overfit. More modern models start with large numbers of neurons and use early-stopping techniques to prevent the models from overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example with Fashion MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a new virtual environment for Tensorflow and Keras\n",
    "* Install Tensorflow and Keras\n",
    "* Check for the version of Tensorflow and Keras that you are using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X, y), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# There are 60,000 images of size 28x28\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE! Each pixel of the image is represended as a value from 0 to 255.\n",
    "# Two problems\n",
    "   # We want a value from 0 to 1\n",
    "   # It is an integer, not a float value\n",
    "# To fix both, divide by 255.0\n",
    "\n",
    "\n",
    "# We have a test set, but we need a validation set:\n",
    "X_valid, X_train = X[:5000] / 255.0 , X[5000:] / 255.0\n",
    "y_valid, y_train = y[:5000], y[5000:]\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "[class_names[y_train[i]] for i in range(20) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.image import imread\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = ['ax1','ax2','ax3','ax4','ax5','ax6','ax7','ax8','ax9','ax10','ax11','ax12','ax13','ax14','ax15','ax16','ax17','ax18','ax19','ax20']\n",
    "f, ax = plt.subplots(1, 20, sharey=True, figsize=(25,6))\n",
    "for i in range(20):\n",
    "    img = ax[i].imshow(X_train[i])\n",
    "    cmap = plt.cm.get_cmap('gray_r')\n",
    "    img.set_cmap(cmap)\n",
    "    ax[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()                        # Input layer - Single stack of layers\n",
    "model.add(keras.layers.Flatten(input_shape=[28,28]))     # Some Preprocessing - converts each input image into a 1D array\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\"))    # Hidden layer\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))    # Hidden layer\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))  # Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is the same as the previous cell\n",
    "\n",
    "from keras.layers import Dense\n",
    "model = keras.models.Sequential([                        # Input layer - Single stack of layers\n",
    "    keras.layers.Flatten(input_shape=[28,28]),           # Some Preprocessing - converts each input image into a 1D array\n",
    "    Dense(300, activation=\"relu\"),                       # Hidden layer\n",
    "    Dense(100, activation=\"relu\"),                       # Hidden layer\n",
    "    Dense(10, activation=\"softmax\")                      # Output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "# \"Param #\" is the number of weights and biases leading into that layer\n",
    "# The first layer has 784 neurons\n",
    "# That is 784*300 connections, so 784*300 weights and 300 biases\n",
    "# total of 235200 + 300 = 235500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of the layers\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get values for all weights leading to a layer\n",
    "weights, biases = model.layers[1].get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",                           # sgd = Stochastic Gradient Descent\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs = 30, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = ['ax1','ax2','ax3']\n",
    "f, ax = plt.subplots(1, 3, sharey=True, figsize=(6,6))\n",
    "for i in range(3):\n",
    "    img = ax[i].imshow(X_test[i])\n",
    "    cmap = plt.cm.get_cmap('gray_r')\n",
    "    img.set_cmap(cmap)\n",
    "    ax[i].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Classes:  \n",
    "# [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "y_prob = model.predict(X_test[:3])\n",
    "y_prob.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get values for all weights leading to a layer\n",
    "weights, biases = model.layers[1].get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save a model for future use\n",
    "model.save(\"FashionMNIST.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load a model that was previously saved\n",
    "loaded_model = keras.models.load_model('FashionMNIST.h5')\n",
    "\n",
    "# Then, use as normal\n",
    "starting_image = 17\n",
    "y_prob = loaded_model.predict(X_test[starting_image:starting_image+3])\n",
    "print(y_prob.round(2))\n",
    "\n",
    "f, ax = plt.subplots(1, 3, sharey=True, figsize=(6,6))\n",
    "for i in range(3):\n",
    "    img = ax[i].imshow(X_test[starting_image+i])\n",
    "    cmap = plt.cm.get_cmap('gray_r')\n",
    "    img.set_cmap(cmap)\n",
    "    ax[i].axis('off')\n",
    "\n",
    "### Classes:  \n",
    "# [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.9 (NeuralNets)",
   "language": "python",
   "name": "neuralnets"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MATH 3480 - Machine Learning\n",
    "# 06 Sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Space\n",
    "Take a black and white picture that is 20x20 pixels. If we take any random assortment of pixels, then we have $2^{400}$ different possible pictures. If you have the possibility of one shade of gray, then you have $3^{400}$ different possible pictures.\n",
    "\n",
    "(Just for comparison, there are thought to be $10^{80}$ nucleans in the universe.\n",
    "\n",
    "Imagine a pixel space - that is, the total number different pixel arrangements you can have to create actual pictures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65536"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "256*256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparsity\n",
    "Take a very large signal as a vector $x$. If we can apply the right transform $\\Psi$, then we can create a vector $s$ that is *sparse*, or mostly zeroes such that,\n",
    "$$x=\\Psi s$$\n",
    "\n",
    "Since $s$ is mostly zeroes, then we only have a certain number of non-zero values, and the storage is much smaller. But to make this work, everyone has to agree on the same format:\n",
    "* .jpg uses DFT or FFT\n",
    "* .jpg2000 uses wavelets\n",
    "\n",
    "A __universal basis__ would use a full transform (that is, $\\Psi$ is a nxn matrix).\n",
    "\n",
    "A __tailored basis__ is an approximated transform (that is, $\\Psi = U_r$ from the SVD, and is a nxr matrix)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compressed Sensing\n",
    "What if you don't have a complete picture? That is, what if you only have a small percentage of the original image? Can we apply a FFT and create the sparse vector $s$ to reconstruct the image?\n",
    "\n",
    "To do this, we take,\n",
    "$$y=Cx=C\\Psi s$$\n",
    "where $y$ is the set of random pixels from the random image, and $C$ would be a matrix that helps us determine which pixels we have. The problem is that since this is underdetermined, there are an infinite number of solutions for $s$. To solve this in the past, we have looked at the 2-norm:\n",
    "$$\\min ||C\\Psi s - y||_2 + \\lambda||s||_2$$\n",
    "where $\\lambda$ is a penalty term. The problem is that the 2-norm in the $\\lambda$ term generates a very dense $s$, which is not what we want. \n",
    "\n",
    "To get it to work, use the 1-norm instead:\n",
    "$$\\min ||C\\Psi s - y||_2 + \\lambda||s||_1$$\n",
    "where $||s||_1 = \\sum_{k=1}^n |s_k|$. This is a convex optimizational problem, meaning it is not combinatorially hard. But it's still not the most efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b8a940844f7f8998522eedb112310c0958420b6c917d0853ef275f15829120cc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit ('DataScience': virtualenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
